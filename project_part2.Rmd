---
title: "Application Part Big Data for Economists Seminar"
author: "Marc Richter and Jingyan Yang"
date: "25 4 2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Set up work space

```{r}

rm(list = ls())

library(rstudioapi)
library(mice)
library(tidyverse)
library(Hmisc)
library(randomForest)
library(doParallel)
library(caret)
library(glmnet)

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

train_data <- read.csv("./training.csv")

X_test <- read.csv("./X_test.csv")


```

## Overview our data

Let's have a look at our data. We have no data set information/fact sheet so we will have to figure out the content ourselves...

```{r, echo=FALSE}
#head(train_data)

summary(train_data)

```

We have the following columns:

* ID: just the row ID
* address: addresses of the homes . sometimes with street name, street number, sometimes only postcode and town... pretty useless. we have the zipcode in an additional column anyway
* area: should be the total built area of the home.
* area_useable: the area of the home including land
* date: date of advertisement release
* date available
* home_type , ca. 190 categories
* municipality . probably won't use, have post code
* newly_built
* price : our dependent variable in this exercise
* rooms : number of rooms
* street: street name, won't use
* year: year of advertisment release
* year_built
* zipcode
* number of dummy variables:
  + balcony
  + basemnt
  + bath_tube
  + building_plot
  + cabletv
  + ceiling
  + cheminee
  + elevator
  + first_time
  + furnished
  + kids_friendly
  + laundry
  + minergie
  + municipality
  + new building
  + oldbuilding
  + oven
  + parking_indoor
  + parking_outside
  + playground
  + pool
  + quiet
  + raisedgroundfloor
  + sale
  + sunny
  + terrace
  + topstorage
  + veranda
  + wheelchair

```{r}
# code from https://www.r-bloggers.com/imputing-missing-data-with-r-mice-package/

pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(train_data,2, pMiss)
```

This looks... bad ..^^

Leaving out all rows with missing data is not an option, as it would leave us with pretty much no data (and for additional reasons like possible bias - the data is most likely not missing completely at random).

One major problem: our dummy variable all only contain ones and NA's. This way, we have no way of knowing which of the NA's are actually NA's and which are 0s.

First approach: Coding all NA's in dummy vars to 0. New meaning of predictor: not "does have ..." but "characteristic ... is mentioned".

```{r}

dummy_cols <- c("balcony", "basement", "bath_tube", "building_plot", "cabletv", "ceiling", "cheminee", "elevator", "first_time", "furnished", "kids_friendly", "laundry", "minergie", "new_building", "oldbuilding", "oven", "parking_indoor", "parking_outside", "playground", "pool", "quiet", "raised_groundfloor", "sale", "sunny", "terrace", "topstorage", "veranda", "wheelchair")

train_without_dummyNA <- train_data %>% mutate_at(.vars = dummy_cols, .funs = funs(ifelse(is.na(.), 0, .)))

apply(train_without_dummyNA,2, pMiss)
```

Let us check for some specific numeric variables, if there are some significant outliers in the dataset.

```{r}
plot(train_without_dummyNA$area) # not real outliers
plot(train_without_dummyNA$floors) # not real outliers
plot(train_without_dummyNA$price) # not real outliers
plot(train_without_dummyNA$rooms) # not real outliers
plot(train_without_dummyNA$year_built) # we could delete the obs. from 1200

train_without_dummyNA <- train_without_dummyNA %>% filter(is.na(year_built) | year_built >=1300) # deletes 4 obs.
```

## Further Adjustments

```{r}

# var format transformations

train_without_dummyNA$price <- as.integer(train_without_dummyNA$price) # price is a factor variable otherwise

# do not use zip code but first three digits of zip code -- otherwise too many clusters having too few observations

train_without_dummyNA$zipcode <- floor(train_without_dummyNA$zipcode/10)
train_without_dummyNA$zipcode <- as.factor(train_without_dummyNA$zipcode) # zipcode should be factor
table(train_without_dummyNA$zipcode)

# delete some useless or redundant variables
train_without_dummyNA <- subset(train_without_dummyNA, select = -c(id, 
                                                                   address, 
                                                                   area_useable, # too many missing values
                                                                   date, # date of ad publishment should not matter
                                                                   date_available, # too sparse information
                                                                   municipality, # we have zip code
                                                                   street)) # again, we use zip code
apply(train_without_dummyNA,2, pMiss)

```

Now we cleaned quite some parts from the dataset . We still have area, floors, rooms and year_built with missing data. For these variables, we will use the mice package to impute them.

## Imputation Part

```{r}
## multiple core computation


# Counts the number of cores on your machine
K <- parallel::detectCores()

# This registers each core as a member of a
# computing cluster

cl <- makeCluster(K)

registerDoParallel(cl)

# using "pmm" method from MICE package, as it needs quite a lot computation we set m=1 and maxit=1
  train_imputed_pmm <- complete(mice(train_imputed, m=40, maxit = 20, meth = "pmm", seed = 50), 1) 
write.csv(train_imputed_pmm, file = "./train_imputed_pmm.csv", row.names = FALSE)

# using "rf" method from MICE package
  train_imputed_rf <- complete(mice(train_imputed, m=40, maxit = 20, meth = "rf", seed = 50), 1) 
write.csv(train_imputed_rf, file = "./train_imputed_rf.csv", row.names = FALSE)
#apply(train_imputation_rf,2, pMiss)

# Once you finished, you deactivate the cluster
# with these two commands.
stopCluster(cl)
registerDoSEQ()

```

## Look at correalation

```{r}

plot(train_imputed_pmm$area, train_imputed_pmm$price) # maybe delete area >600 # relationship seems pretty much linear - but really can't tell, so many observations

plot(train_imputed_pmm$floors, train_imputed_pmm$price) # no relationship detectable

plot(train_imputed_pmm$rooms, train_imputed_pmm$price) # no relationship detectable

plot(train_imputed_pmm$year, train_imputed_pmm$price) # no relationship detectable

plot(train_imputed_pmm$year_built, train_imputed_pmm$price) # no relationship detectable
```

Really hard to detect any relationship.

Trying out a linear regression with k fold cross validation.

```{r}

# Split the data into training and test set
set.seed(123)
training.samples <- train_lin_subset$price %>%
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- train_lin_subset[training.samples, ]
test.data <- train_lin_subset[-training.samples, ]
# Build the model
lm_fit <- lm(price ~., data = train.data)

## test for influential observations via cooks distance
cooksd <- cooks.distance(lm_fit)

plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4*mean(cooksd, na.rm=T), col="green")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="blue")  # add labels
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])  # influential row numbers
head(train.data[influential, ])  # influential observations.

# delete influential data points

train.data_without_outliers <- train.data[-influential,]

# new model 

lm_fit_without_outliers <- lm(price ~., data = train.data_without_outliers)

# Make predictions and compute the R2, RMSE and MAE
predictions <- lm_fit %>% predict(test.data)
predictions_without_outliers <- lm_fit_without_outliers %>% predict(test.data)
data.frame( R2 = R2(predictions, test.data$price),
            RMSE = RMSE(predictions, test.data$price),
            MAE = MAE(predictions, test.data$price))

data.frame( R2 = R2(predictions_without_outliers, test.data$price),
            RMSE = RMSE(predictions_without_outliers, test.data$price),
            MAE = MAE(predictions_without_outliers, test.data$price))
```

Our validation set error is pretty high, and deleting outlier observations does not considerably change this. We should try out different approaches.


## Moving to LASSO
Our data has quite some variables. Especially as we redifined NA's to 0 in the case of dummy variables and imputed the other ones, this can introduce bias. Also, we do not want our model to get into the trap of what is known as "the curse of dimensionality". One way to work against this is to build a LASSO Model - which is designed to force coefficients to get exactly zero. This way, we might be able to drop some variables which do not have good explanational power.

```{r}
# reform X (training and test) and Y training for lasso input
lasso_x <- model.matrix(price ~., train.data)[,-1]
lasso_y <- train.data$price

test_x <- model.matrix(price ~., test.data)[,-1]
test_y <- test.data$price
# fit model 

lasso_fit <- glmnet(lasso_x, lasso_y, alpha = 1)
set.seed(1)
cv.out <- cv.glmnet(lasso_x, lasso_y, alpha = 1)
bestlam <- cv.out$lambda.min
lasso_pred <- predict(lasso_fit, s = bestlam, newx = test_x)
mean((lasso_pred - test_y)^2)

out <- glmnet(lasso_x, lasso_y, alpha = 1)
lasso.coef <- predict(out, type = "coefficients", s= bestlam)[1:20,]
 
lasso.coef[lasso.coef != 0]
```
Our lasso model has the advantage that there is only 15 predictors left which are used for computing the estimates. However, our MSE is huge - some orders of magnitude higher than the error for the linear model.

## Imputation of the test dataset .

```{r}
# substitute NA's in dummy vars with 0
X_test_without_dummyNA <- X_test %>% mutate_at(.vars = dummy_cols, .funs = funs(ifelse(is.na(.), 0, .)))

# delete some useless or redundant variables
X_test_imputed <- subset(X_test_without_dummyNA, select = -c(id, address, area_useable, date, date_available, municipality, street))

apply(X_test_without_dummyNA,2, pMiss)

summary(X_test_without_dummyNA)
## multiple core computation


# Counts the number of cores on your machine
K <- parallel::detectCores()

# This registers each core as a member of a
# computing cluster

cl <- makeCluster(K)

registerDoParallel(cl)

# using "pmm" method from MICE package, as it needs quite a lot computation we set m=1 and maxit=1
  X_test_imputed_pmm <- complete(mice(X_test_imputed, m=2, maxit = 5, meth = "pmm", seed = 50), 1) 
write.csv(X_test_imputed_pmm, file = "./X_test_imputed_pmm.csv", row.names = FALSE)

# using "rf" method from MICE package
  train_imputed_rf <- complete(mice(train_imputed, m=2, maxit = 5, meth = "rf", seed = 50), 1) 
write.csv(train_imputed_rf, file = "./train_imputed_rf.csv", row.names = FALSE)
#apply(train_imputation_rf,2, pMiss)

# Once you finished, you deactivate the cluster
# with these two commands.
stopCluster(cl)
registerDoSEQ()

```